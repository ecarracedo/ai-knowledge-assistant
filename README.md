# ðŸ§  Proyecto: AI Knowledge Assistant (Agente RAG)

Un asistente inteligente capaz de responder preguntas sobre una base de conocimiento propia (por ejemplo, documentos tÃ©cnicos, PDFs de producto o una base SQL).

## ðŸŽ¯ Objetivo

Construir un agente LLM con RAG (Retrieval-Augmented Generation) que:

- Incruste (embed) documentos o textos.
- Busque informaciÃ³n relevante con similitud semÃ¡ntica.
- Responda usando un LLM con contexto.
- Exponga una API (FastAPI) y una interfaz (Streamlit).
- EvalÃºe la calidad de respuestas (cosine similarity).

## ðŸ§© Stack

- LangChain o LangGraph (core de orquestaciÃ³n)
- ChromaDB (vector store)
- OpenAI o HuggingFace (embeddings y LLM)
- FastAPI (backend)
- Streamlit o Gradio (frontend)
- Pytest (tests)
- Docker (deployment opcional)

## ðŸ“‚ Estructura del proyecto
```
ai-knowledge-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                # FastAPI app
â”‚   â”œâ”€â”€ rag_pipeline.py        # RAG logic
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ loader.py          # Document/data loading
â”‚   â”‚   â”œâ”€â”€ evaluator.py       # Response similarity metric
â”‚   â”‚   â””â”€â”€ config.py          # API keys/settings management
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ ui.py                  # Streamlit/Gradio interface
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_agent.py          # Basic unit tests
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env.example
```
